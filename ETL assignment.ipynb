{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "151316de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine\n",
    "import urllib\n",
    "import requests\n",
    "import json\n",
    "import shutil\n",
    "from datetime import datetime as dt\n",
    "from config import password\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634a1aba",
   "metadata": {},
   "source": [
    "# Comparing new imported data to local CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e3060b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "importData = \"newsample2.csv\" # input filename for either CSV or imported access data\n",
    "localData = \"sampleDB.csv\" # input filename for local delayCSV DB\n",
    "newFullData_df = pd.read_csv(importData).fillna(0)\n",
    "localDB_df = pd.read_csv(localData).fillna(0)\n",
    "topColumns = ['DATE','TIME','DEST','LOCATION','CAUSE','COD','DEL','SEC','LR','HR','OFF','CNC','RUN']\n",
    "newData_df = newFullData_df[topColumns]\n",
    "# localDB_df.head(2)\n",
    "# newData_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e33f582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-83de9751f90a>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  newData_df['DEL'] = newData_df['DEL'].astype('int')\n",
      "<ipython-input-3-83de9751f90a>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  newData_df['SEC'] = newData_df['SEC'].astype('int')\n",
      "<ipython-input-3-83de9751f90a>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  newData_df['LR'] = newData_df['LR'].astype('int')\n",
      "<ipython-input-3-83de9751f90a>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  newData_df['HR'] = newData_df['HR'].astype('int')\n",
      "<ipython-input-3-83de9751f90a>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  newData_df['OFF'] = newData_df['OFF'].astype('int')\n",
      "<ipython-input-3-83de9751f90a>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  newData_df['CNC'] = newData_df['CNC'].astype('int')\n",
      "<ipython-input-3-83de9751f90a>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  newData_df['RUN'] = newData_df['RUN'].astype('int')\n",
      "<ipython-input-3-83de9751f90a>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  newData_df['TIME']= import_newTimes\n"
     ]
    }
   ],
   "source": [
    "# Compare import and local data for new changes\n",
    "if len(localDB_df)>0:\n",
    "    # Format new input data types\n",
    "    newData_df['DEL'] = newData_df['DEL'].astype('int')\n",
    "    newData_df['SEC'] = newData_df['SEC'].astype('int')\n",
    "    newData_df['LR'] = newData_df['LR'].astype('int')\n",
    "    newData_df['HR'] = newData_df['HR'].astype('int')\n",
    "    newData_df['OFF'] = newData_df['OFF'].astype('int')\n",
    "    newData_df['CNC'] = newData_df['CNC'].astype('int')\n",
    "    newData_df['RUN'] = newData_df['RUN'].astype('int')\n",
    "    \n",
    "    # Format new input time column\n",
    "    import_dtFormat =pd.to_datetime(newData_df['TIME'], format='%H%M')\n",
    "    import_newTimes= import_dtFormat.apply(lambda x:x.strftime(\"%H:%M\"))\n",
    "    newData_df['TIME']= import_newTimes\n",
    "    \n",
    "    # Compare new input data to local DB data\n",
    "    compare = newData_df.merge(localDB_df, on=[\"DATE\",\"TIME\",\"LOCATION\"], how='outer', indicator=True)\n",
    "    updateData = compare.loc[compare['_merge']==\"left_only\"]\n",
    "    dirtyData = updateData.dropna(axis=1)\n",
    "    dirtyData.columns = dirtyData.columns.str.strip('_x')\n",
    "    \n",
    "    # Drop merge column\n",
    "    cleanData_df = dirtyData.drop(columns='merge')\n",
    "else:\n",
    "        # Format new input data types\n",
    "    newData_df['DEL'] = newData_df['DEL'].astype('int')\n",
    "    newData_df['SEC'] = newData_df['SEC'].astype('int')\n",
    "    newData_df['LR'] = newData_df['LR'].astype('int')\n",
    "    newData_df['HR'] = newData_df['HR'].astype('int')\n",
    "    newData_df['OFF'] = newData_df['OFF'].astype('int')\n",
    "    newData_df['CNC'] = newData_df['CNC'].astype('int')\n",
    "    newData_df['RUN'] = newData_df['RUN'].astype('int')\n",
    "    \n",
    "    # Format new input time column\n",
    "    import_dtFormat =pd.to_datetime(newData_df['TIME'], format='%H%M')\n",
    "    import_newTimes= import_dtFormat.apply(lambda x:x.strftime(\"%H:%M\"))\n",
    "    newData_df['TIME']= import_newTimes\n",
    "    \n",
    "    cleanData_df = newData_df   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e0046a",
   "metadata": {},
   "source": [
    "### Append new delay data to local CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ab5a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "delayDatabase_path = \"sampleDB.csv\" # add path for local delayCSV DB to be appended\n",
    "cleanData_df.to_csv(delayDatabase_path, mode='a', index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d363dfc",
   "metadata": {},
   "source": [
    "# Upload local delay data to PG database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950b013b",
   "metadata": {},
   "source": [
    "### Import local delay CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "231eefbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import local CSV data\n",
    "delay_file = \"sampleDB.csv\" # add filename for local delayCSV DB\n",
    "delayData_df = pd.read_csv(delay_file).fillna(0)\n",
    "exportData_df = delayData_df.copy()\n",
    "# len(exportData_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f874c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns\n",
    "exportData_df['latetrains'] = \"\"\n",
    "exportData_df['latetrains_OFF_CNC'] = \"\"\n",
    "exportData_df['ten_min_delay'] = \"\"\n",
    "exportData_df['qualifying_delay'] = \"\"\n",
    "exportData_df['cod_defined'] = \"\"\n",
    "# exportData_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d25eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns\n",
    "DEL = exportData_df['DEL']\n",
    "SEC = exportData_df['SEC']\n",
    "LR = exportData_df['LR']\n",
    "HR = exportData_df['HR']\n",
    "# OFF = exportData_df['OFF']\n",
    "# CNC = exportData_df['CNC']\n",
    "COD = exportData_df['COD']\n",
    "# LT = exportData_df['Late Trains']\n",
    "# LTOC = exportData_df['Late Trains +OFF+CNC']\n",
    "tenPlus = exportData_df['ten_min_delay']\n",
    "QD = exportData_df['qualifying_delay']\n",
    "causeDef = exportData_df['cod_defined']\n",
    "\n",
    "# Calc Late trains column\n",
    "LTdata = []\n",
    "\n",
    "for x in range(len(exportData_df)):\n",
    "    if DEL[x]==0:\n",
    "        LTdata.append(int(SEC[x]))\n",
    "    elif DEL[x]>0:\n",
    "        LTdata.append(1 + int(SEC[x]))\n",
    "    else:\n",
    "        LTdata.append(0)\n",
    "exportData_df['latetrains'] = LTdata\n",
    "        \n",
    "    \n",
    "# Calc LT+OFF+CNC column\n",
    "OFF = exportData_df['OFF']\n",
    "CNC = exportData_df['CNC']\n",
    "LT = exportData_df['latetrains']\n",
    "\n",
    "LTOCdata = []\n",
    "\n",
    "for x in range(len(exportData_df)):\n",
    "    delaySum = int(float(LT[x])) + int(float(OFF[x])) + int(float(CNC[x]))\n",
    "    LTOCdata.append(delaySum)\n",
    "exportData_df['latetrains_OFF_CNC'] = LTOCdata\n",
    "\n",
    "\n",
    "# Calc 10+min Delay column\n",
    "tenData = []\n",
    "\n",
    "for x in range(len(exportData_df)):\n",
    "    if (DEL[x]>= 10) or (LR[x]>= 10) or (HR[x]>= 10):\n",
    "        tenData.append('YES')\n",
    "    else:\n",
    "        tenData.append('NO')\n",
    "exportData_df['ten_min_delay'] = tenData\n",
    "        \n",
    "    \n",
    "# Calc Qualifying Delay column\n",
    "LTOC = exportData_df['latetrains_OFF_CNC']\n",
    "\n",
    "qdData = []\n",
    "\n",
    "for x in range(len(exportData_df)):\n",
    "    if (int(LTOC[x])>=5) or (tenPlus[x]==\"YES\"):\n",
    "        qdData.append('YES')\n",
    "    else:\n",
    "        qdData.append('NO')\n",
    "exportData_df['qualifying_delay'] = qdData\n",
    "\n",
    "\n",
    "# Calc COD defined column\n",
    "codData = []\n",
    "\n",
    "shortCauses = {\"ot\":\"TO Procedure\",\n",
    "               \"oc\":\"Controller Procedure\",\n",
    "               \"os\":\"Station Opened Late\",\n",
    "               \"oy\":\"Yard\",\n",
    "               \"oz\":\"Misc\",\n",
    "               \"od\":\"Late Dispatch\",\n",
    "               \"ol\":\"Traffic interference\"\n",
    "              }\n",
    "causes = list(shortCauses.keys())\n",
    "\n",
    "for x in range(len(exportData_df)):\n",
    "    if COD[x] in causes:\n",
    "        codData.append(shortCauses[COD[x]])\n",
    "    else:\n",
    "        codData.append(\"N/A\")\n",
    "exportData_df['cod_defined'] = codData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dec30ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportData_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09e2465",
   "metadata": {},
   "source": [
    "### Export data to PG database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c71d3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload station data to transportationDB\n",
    "uploadFile = exportData_df.rename(columns=str.lower)\n",
    "\n",
    "pg_engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost/transportationDB')\n",
    "uploadFile.to_sql(name='opsdelays', con=pg_engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ebe807",
   "metadata": {},
   "source": [
    "## Import BART station data from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ff2bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Bart API and pull station information\n",
    "base_url=\"http://api.bart.gov/api/stn.aspx?cmd=stns&key=MW9S-E7SL-26DU-VV8V&json=y\"\n",
    "response = requests.get(base_url)\n",
    "results = response.json()\n",
    "stationData = results['root']['stations']['station']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11624fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>abbr</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12th St. Oakland City Center</td>\n",
       "      <td>12TH</td>\n",
       "      <td>37.803768</td>\n",
       "      <td>-122.271450</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>alameda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16th St. Mission</td>\n",
       "      <td>16TH</td>\n",
       "      <td>37.765062</td>\n",
       "      <td>-122.419694</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>sanfrancisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19th St. Oakland</td>\n",
       "      <td>19TH</td>\n",
       "      <td>37.808350</td>\n",
       "      <td>-122.268602</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>alameda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24th St. Mission</td>\n",
       "      <td>24TH</td>\n",
       "      <td>37.752470</td>\n",
       "      <td>-122.418143</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>sanfrancisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antioch</td>\n",
       "      <td>ANTC</td>\n",
       "      <td>37.995388</td>\n",
       "      <td>-121.780420</td>\n",
       "      <td>Antioch</td>\n",
       "      <td>Contra Costa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  abbr        lat         long           city  \\\n",
       "0  12th St. Oakland City Center  12TH  37.803768  -122.271450        Oakland   \n",
       "1              16th St. Mission  16TH  37.765062  -122.419694  San Francisco   \n",
       "2              19th St. Oakland  19TH  37.808350  -122.268602        Oakland   \n",
       "3              24th St. Mission  24TH  37.752470  -122.418143  San Francisco   \n",
       "4                       Antioch  ANTC  37.995388  -121.780420        Antioch   \n",
       "\n",
       "         county  \n",
       "0       alameda  \n",
       "1  sanfrancisco  \n",
       "2       alameda  \n",
       "3  sanfrancisco  \n",
       "4  Contra Costa  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert station info to dataframe \n",
    "stationData_df = pd.DataFrame(stationData)\n",
    "renamedData = stationData_df.rename(columns={\"gtfs_latitude\":\"lat\",\n",
    "                               \"gtfs_longitude\":\"long\",\n",
    "                               })\n",
    "short_stationData_df = renamedData[['name','abbr','lat','long','city','county']]\n",
    "short_stationData_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd8eec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload station data to OperationsDB\n",
    "engine = create_engine(f'postgresql+psycopg2://postgres:{password}@localhost/transportationDB')\n",
    "short_stationData_df.to_sql(name='stations', con=engine, if_exists='append', index_label='station_no')\n",
    "# engine.execute(\"SELECT * FROM stations\").first()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
